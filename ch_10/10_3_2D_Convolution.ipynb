{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "ce5496c2",
            "metadata": {},
            "source": "<a href=\"https://colab.research.google.com/github/udlbook/udlbook/blob/main/Notebooks/Chap10/10_3_2D_Convolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
        },
        {
            "cell_type": "markdown",
            "id": "818ed04b",
            "metadata": {},
            "source": "# **Notebook 10.3: 2D Convolution**\n\nThis notebook investigates the 2D convolution operation.  It asks you to hand code the convolution so we can be sure that we are computing the same thing as in PyTorch.  The next notebook uses the convolutional layers in PyTorch directly.\n\nWork through the cells below, running each cell in turn. In various places you will see the words \"TO DO\". Follow the instructions at these places and make predictions about what is going to happen or write code to complete the functions.\n\nContact me at udlbookmail@gmail.com if you find any mistakes or have any suggestions."
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "115b868e",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "import numpy as np\nimport torch\n# Set to print in reasonable form\nnp.set_printoptions(precision=3, floatmode=\"fixed\")\ntorch.set_printoptions(precision=3)"
        },
        {
            "cell_type": "markdown",
            "id": "ed928854",
            "metadata": {},
            "source": "This routine performs convolution in PyTorch"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "f80ebf20",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "# Perform convolution in PyTorch\ndef conv_pytorch(image, conv_weights, stride=1, pad =1):\n  # Convert image and kernel to tensors\n  image_tensor = torch.from_numpy(image) # (batchSize, channelsIn, imageHeightIn, =imageWidthIn)\n  conv_weights_tensor = torch.from_numpy(conv_weights) # (channelsOut, channelsIn, kernelHeight, kernelWidth)\n  # Do the convolution\n  output_tensor = torch.nn.functional.conv2d(image_tensor, conv_weights_tensor, stride=stride, padding=pad)\n  # Convert back from PyTorch and return\n  return(output_tensor.numpy()) # (batchSize channelsOut imageHeightOut imageHeightIn)"
        },
        {
            "cell_type": "markdown",
            "id": "4426d07a",
            "metadata": {},
            "source": "First we'll start with the simplest 2D convolution.  Just one channel in and one channel out.  A single image in the batch."
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "bc59b163",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "# Perform convolution in numpy\ndef conv_numpy_1(image, weights, pad=1):\n\n    # Perform zero padding\n    if pad != 0:\n        image = np.pad(image, ((0, 0), (0 ,0), (pad, pad), (pad, pad)),'constant')\n\n    # Get sizes of image array and kernel weights\n    batchSize,  channelsIn, imageHeightIn, imageWidthIn = image.shape\n    channelsOut, channelsIn, kernelHeight, kernelWidth = weights.shape\n\n    # Get size of output arrays\n    imageHeightOut = np.floor(1 + imageHeightIn - kernelHeight).astype(int)\n    imageWidthOut = np.floor(1 + imageWidthIn - kernelWidth).astype(int)\n\n    # Create output\n    out = np.zeros((batchSize, channelsOut, imageHeightOut, imageWidthOut), dtype=np.float32)\n\n    # !!!!!! NOTE THERE IS A SUBTLETY HERE !!!!!!!!\n    # I have padded the image with zeros above, so it is surrouned by a \"ring\" of zeros\n    # That means that the image indexes are all off by one\n    # This actually makes your code simpler\n\n    for c_y in range(imageHeightOut):\n      for c_x in range(imageWidthOut):\n        for c_kernel_y in range(kernelHeight):\n          for c_kernel_x in range(kernelWidth):\n            # TODO -- Retrieve the image pixel and the weight from the convolution\n            # Only one image in batch, one input channel and one output channel, so these indices should all be zero\n            # Replace the two lines below\n            this_pixel_value = image[0, 0, c_y+c_kernel_y, c_x + c_kernel_x]\n            this_weight = weights[0, 0, c_kernel_y, c_kernel_x]\n\n\n            # Multiply these together and add to the output at this position\n            out[0, 0, c_y, c_x] += this_pixel_value * this_weight\n\n    return out"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "5fd6f7db",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "PyTorch Results\n[[[[-0.929 -2.760  0.716  0.114  0.560 -0.387]\n   [-1.515  0.283  1.008  0.466 -1.094  2.004]\n   [-1.634  3.555 -2.154 -0.892 -1.856  2.299]\n   [ 0.565 -0.947 -0.629  2.996 -1.811 -0.533]]]]\nYour results\n[[[[-0.929 -2.760  0.716  0.114  0.560 -0.387]\n   [-1.515  0.283  1.008  0.466 -1.094  2.004]\n   [-1.634  3.555 -2.154 -0.892 -1.856  2.299]\n   [ 0.565 -0.947 -0.629  2.996 -1.811 -0.533]]]]\n"
                }
            ],
            "source": "# Set random seed so we always get same answer\nnp.random.seed(1)\nn_batch = 1\nimage_height = 4\nimage_width = 6\nchannels_in = 1\nkernel_size = 3\nchannels_out = 1\n\n# Create random input image\ninput_image= np.random.normal(size=(n_batch, channels_in, image_height, image_width))\n# Create random convolution kernel weights\nconv_weights = np.random.normal(size=(channels_out, channels_in, kernel_size, kernel_size))\n\n# Perform convolution using PyTorch\nconv_results_pytorch = conv_pytorch(input_image, conv_weights, stride=1, pad=1)\nprint(\"PyTorch Results\")\nprint(conv_results_pytorch)\n\n# Perform convolution in numpy\nprint(\"Your results\")\nconv_results_numpy = conv_numpy_1(input_image, conv_weights)\nprint(conv_results_numpy)"
        },
        {
            "cell_type": "markdown",
            "id": "8f2dab8a",
            "metadata": {},
            "source": "Let's now add in the possibility of using different strides"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "b6ec9455",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "# Perform convolution in numpy\ndef conv_numpy_2(image, weights, stride=1, pad=1):\n\n    # Perform zero padding\n    if pad != 0:\n        image = np.pad(image, ((0, 0), (0 ,0), (pad, pad), (pad, pad)),'constant')\n\n    # Get sizes of image array and kernel weights\n    batchSize,  channelsIn, imageHeightIn, imageWidthIn = image.shape\n    channelsOut, channelsIn, kernelHeight, kernelWidth = weights.shape\n\n    # Get size of output arrays\n    imageHeightOut = np.floor(1 + (imageHeightIn - kernelHeight) / stride).astype(int)\n    imageWidthOut = np.floor(1 + (imageWidthIn - kernelWidth) / stride).astype(int)\n\n    # Create output\n    out = np.zeros((batchSize, channelsOut, imageHeightOut, imageWidthOut), dtype=np.float32)\n\n    for c_y in range(imageHeightOut):\n      for c_x in range(imageWidthOut):\n        for c_kernel_y in range(kernelHeight):\n          for c_kernel_x in range(kernelWidth):\n            # TODO -- Retrieve the image pixel and the weight from the convolution\n            # Only one image in batch, one input channel and one output channel, so these indices should all be zero\n            # Replace the two lines below\n            # 'p' is for picture\n            p_y_index = c_y * stride\n            p_x_index = c_x * stride\n            this_pixel_value = image[0, 0, p_y_index + c_kernel_y, p_x_index + c_kernel_x]\n            this_weight = weights[0, 0, c_kernel_y, c_kernel_x]\n\n\n\n            # Multiply these together and add to the output at this position\n            out[0, 0, c_y, c_x] += np.sum(this_pixel_value * this_weight)\n\n    return out"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "1db9d2ff",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "PyTorch Results\n[[[[-0.809 -4.550 -5.486 -9.506 -4.512]\n   [-0.055  1.145 -5.388 -3.910  0.097]\n   [-0.186  0.660  1.630  2.275  4.874]\n   [ 2.386 -0.225  3.288 -4.239 -1.403]\n   [ 0.825  1.710 -3.246  3.246  1.709]\n   [ 0.809  3.695  3.491 -2.113 -2.714]]]]\nYour results\n0.0 -0.024616955875778355\n0.0 -0.7751616191691596\n0.0 1.2737559301587766\n0.0 1.9671017492547347\n1.6243453636632417 -1.857981864446752\n-0.6117564136500754 1.2361640304528203\n0.0 1.6276507531489064\n1.462107937044974 0.3380116965744758\n-2.060140709497654 -1.199268032335186\n0.0 -0.024616955875778355\n0.0 -0.7751616191691596\n0.0 1.2737559301587766\n-0.6117564136500754 1.9671017492547347\n-0.5281717522634557 -1.857981864446752\n-1.0729686221561705 1.2361640304528203\n-2.060140709497654 1.6276507531489064\n-0.3224172040135075 0.3380116965744758\n-0.38405435466841564 -1.199268032335186\n0.0 -0.024616955875778355\n0.0 -0.7751616191691596\n0.0 1.2737559301587766\n-1.0729686221561705 1.9671017492547347\n0.8654076293246785 -1.857981864446752\n-2.3015386968802827 1.2361640304528203\n-0.38405435466841564 1.6276507531489064\n1.1337694423354374 0.3380116965744758\n-1.0998912673140309 -1.199268032335186\n0.0 -0.024616955875778355\n0.0 -0.7751616191691596\n0.0 1.2737559301587766\n-2.3015386968802827 1.9671017492547347\n1.74481176421648 -1.857981864446752\n-0.7612069008951028 1.2361640304528203\n-1.0998912673140309 1.6276507531489064\n-0.17242820755043575 0.3380116965744758\n-0.8778584179213718 -1.199268032335186\n0.0 -0.024616955875778355\n0.0 -0.7751616191691596\n0.0 1.2737559301587766\n-0.7612069008951028 1.9671017492547347\n0.31903909605709857 -1.857981864446752\n-0.2493703754774101 1.2361640304528203\n-0.8778584179213718 1.6276507531489064\n0.04221374671559283 0.3380116965744758\n0.5828152137158222 -1.199268032335186\n0.0 -0.024616955875778355\n1.462107937044974 -0.7751616191691596\n-2.060140709497654 1.2737559301587766\n0.0 1.9671017492547347\n-1.1006191772129212 -1.857981864446752\n1.1447237098396141 1.2361640304528203\n0.0 1.6276507531489064\n-0.691660751725309 0.3380116965744758\n-0.39675352685597737 -1.199268032335186\n-2.060140709497654 -0.024616955875778355\n-0.3224172040135075 -0.7751616191691596\n-0.38405435466841564 1.2737559301587766\n1.1447237098396141 1.9671017492547347\n0.9015907205927955 -1.857981864446752\n0.5024943389018682 1.2361640304528203\n-0.39675352685597737 1.6276507531489064\n-0.6871727001195994 0.3380116965744758\n-0.8452056414987196 -1.199268032335186\n-0.38405435466841564 -0.024616955875778355\n1.1337694423354374 -0.7751616191691596\n-1.0998912673140309 1.2737559301587766\n0.5024943389018682 1.9671017492547347\n0.9008559492644118 -1.857981864446752\n-0.6837278591743331 1.2361640304528203\n-0.8452056414987196 1.6276507531489064\n-0.671246130836819 0.3380116965744758\n-0.01266459891890136 -1.199268032335186\n-1.0998912673140309 -0.024616955875778355\n-0.17242820755043575 -0.7751616191691596\n-0.8778584179213718 1.2737559301587766\n-0.6837278591743331 1.9671017492547347\n-0.12289022551864817 -1.857981864446752\n-0.9357694342590688 1.2361640304528203\n-0.01266459891890136 1.6276507531489064\n-1.1173103486352778 0.3380116965744758\n0.23441569781709215 -1.199268032335186\n-0.8778584179213718 -0.024616955875778355\n0.04221374671559283 -0.7751616191691596\n0.5828152137158222 1.2737559301587766\n-0.9357694342590688 1.9671017492547347\n-0.2678880796260159 -1.857981864446752\n0.530355466738186 1.2361640304528203\n0.23441569781709215 1.6276507531489064\n1.6598021771098705 0.3380116965744758\n0.7420441605773356 -1.199268032335186\n0.0 -0.024616955875778355\n-0.691660751725309 -0.7751616191691596\n-0.39675352685597737 1.2737559301587766\n0.0 1.9671017492547347\n-0.19183555236161492 -1.857981864446752\n-0.8876289640848363 1.2361640304528203\n0.0 1.6276507531489064\n0.3001703199558275 0.3380116965744758\n-0.35224984649351865 -1.199268032335186\n-0.39675352685597737 -0.024616955875778355\n-0.6871727001195994 -0.7751616191691596\n-0.8452056414987196 1.2737559301587766\n-0.8876289640848363 1.9671017492547347\n-0.7471582937508376 -1.857981864446752\n1.6924546010277466 1.2361640304528203\n-0.35224984649351865 1.6276507531489064\n-1.1425181980221402 0.3380116965744758\n-0.3493427224128775 -1.199268032335186\n-0.8452056414987196 -0.024616955875778355\n-0.671246130836819 -0.7751616191691596\n-0.01266459891890136 1.2737559301587766\n1.6924546010277466 1.9671017492547347\n0.05080775477602897 -1.857981864446752\n-0.6369956465693534 1.2361640304528203\n-0.3493427224128775 1.6276507531489064\n-0.2088942333747781 0.3380116965744758\n0.5866231911821976 -1.199268032335186\n-0.01266459891890136 -0.024616955875778355\n-1.1173103486352778 -0.7751616191691596\n0.23441569781709215 1.2737559301587766\n-0.6369956465693534 1.9671017492547347\n0.19091548466746602 -1.857981864446752\n2.100255136478842 1.2361640304528203\n0.5866231911821976 1.6276507531489064\n0.8389834138745049 0.3380116965744758\n0.9311020813035573 -1.199268032335186\n0.23441569781709215 -0.024616955875778355\n1.6598021771098705 -0.7751616191691596\n0.7420441605773356 1.2737559301587766\n2.100255136478842 1.9671017492547347\n0.12015895248162915 -1.857981864446752\n0.6172031097074192 1.2361640304528203\n0.9311020813035573 1.6276507531489064\n0.2855873252542588 0.3380116965744758\n0.8851411642707281 -1.199268032335186\n0.0 -0.024616955875778355\n0.3001703199558275 -0.7751616191691596\n-0.35224984649351865 1.2737559301587766\n0.0 1.9671017492547347\n-0.7543979409966528 -1.857981864446752\n1.2528681552332879 1.2361640304528203\n0.0 1.6276507531489064\n-1.4441138054295894 0.3380116965744758\n-0.5044658629464512 -1.199268032335186\n-0.35224984649351865 -0.024616955875778355\n-1.1425181980221402 -0.7751616191691596\n-0.3493427224128775 1.2737559301587766\n1.2528681552332879 1.9671017492547347\n0.5129298204180088 -1.857981864446752\n-0.29809283510271567 1.2361640304528203\n-0.5044658629464512 1.6276507531489064\n0.16003706944783047 0.3380116965744758\n0.8761689211162249 -1.199268032335186\n-0.3493427224128775 -0.024616955875778355\n-0.2088942333747781 -0.7751616191691596\n0.5866231911821976 1.2737559301587766\n-0.29809283510271567 1.9671017492547347\n0.48851814653749703 -1.857981864446752\n-0.07557171302105573 1.2361640304528203\n0.8761689211162249 1.6276507531489064\n0.31563494724160523 0.3380116965744758\n-2.022201215824003 -1.199268032335186\n0.5866231911821976 -0.024616955875778355\n0.8389834138745049 -0.7751616191691596\n0.9311020813035573 1.2737559301587766\n-0.07557171302105573 1.9671017492547347\n1.131629387451427 -1.857981864446752\n1.5198168164221988 1.2361640304528203\n-2.022201215824003 1.6276507531489064\n-0.3062040126283718 0.3380116965744758\n0.8279746426072462 -1.199268032335186\n0.9311020813035573 -0.024616955875778355\n0.2855873252542588 -0.7751616191691596\n0.8851411642707281 1.2737559301587766\n1.5198168164221988 1.9671017492547347\n2.1855754065331614 -1.857981864446752\n-1.3964963354881377 1.2361640304528203\n0.8279746426072462 1.6276507531489064\n0.2300947353643834 0.3380116965744758\n0.7620111803120247 -1.199268032335186\n0.0 -0.024616955875778355\n-1.4441138054295894 -0.7751616191691596\n-0.5044658629464512 1.2737559301587766\n0.0 1.9671017492547347\n-0.22232814261035927 -1.857981864446752\n-0.20075806892999745 1.2361640304528203\n0.0 1.6276507531489064\n1.198917879901507 0.3380116965744758\n0.18515641748394385 -1.199268032335186\n-0.5044658629464512 -0.024616955875778355\n0.16003706944783047 -0.7751616191691596\n0.8761689211162249 1.2737559301587766\n-0.20075806892999745 1.9671017492547347\n0.1865613909882843 -1.857981864446752\n0.4100516472082563 1.2361640304528203\n0.18515641748394385 1.6276507531489064\n-0.3752849500901142 0.3380116965744758\n-0.6387304074542224 -1.199268032335186\n0.8761689211162249 -0.024616955875778355\n0.31563494724160523 -0.7751616191691596\n-2.022201215824003 1.2737559301587766\n0.4100516472082563 1.9671017492547347\n0.19829972012676975 -1.857981864446752\n0.11900864580745882 1.2361640304528203\n-0.6387304074542224 1.6276507531489064\n0.4234943540641129 0.3380116965744758\n0.07734006834855942 -1.199268032335186\n-2.022201215824003 -0.024616955875778355\n-0.3062040126283718 -0.7751616191691596\n0.8279746426072462 1.2737559301587766\n0.11900864580745882 1.9671017492547347\n-0.6706622862890306 -1.857981864446752\n0.3775637863209194 1.2361640304528203\n0.07734006834855942 1.6276507531489064\n-0.3438536755710756 0.3380116965744758\n0.04359685683424694 -1.199268032335186\n0.8279746426072462 -0.024616955875778355\n0.2300947353643834 -0.7751616191691596\n0.7620111803120247 1.2737559301587766\n0.3775637863209194 1.9671017492547347\n0.12182127099143693 -1.857981864446752\n1.1294839079119197 1.2361640304528203\n0.04359685683424694 1.6276507531489064\n-0.6200008439481293 0.3380116965744758\n0.6980320340722189 -1.199268032335186\n0.0 -0.024616955875778355\n1.198917879901507 -0.7751616191691596\n0.18515641748394385 1.2737559301587766\n0.0 1.9671017492547347\n-0.4471285647859982 -1.857981864446752\n1.2245077048054989 1.2361640304528203\n0.0 1.6276507531489064\n-1.3731173202467557 0.3380116965744758\n0.31515939204229176 -1.199268032335186\n0.18515641748394385 -0.024616955875778355\n-0.3752849500901142 -0.7751616191691596\n-0.6387304074542224 1.2737559301587766\n1.2245077048054989 1.9671017492547347\n0.4034916417908 -1.857981864446752\n0.593578523237067 1.2361640304528203\n0.31515939204229176 1.6276507531489064\n0.8461606475850334 0.3380116965744758\n-0.8595159408319863 -1.199268032335186\n-0.6387304074542224 -0.024616955875778355\n0.4234943540641129 -0.7751616191691596\n0.07734006834855942 1.2737559301587766\n0.593578523237067 1.9671017492547347\n-1.0949118457410418 -1.857981864446752\n0.1693824330586681 1.2361640304528203\n-0.8595159408319863 1.6276507531489064\n0.35054597866410736 0.3380116965744758\n-1.3122834112374318 -1.199268032335186\n0.07734006834855942 -0.024616955875778355\n-0.3438536755710756 -0.7751616191691596\n0.04359685683424694 1.2737559301587766\n0.1693824330586681 1.9671017492547347\n0.7405564510962748 -1.857981864446752\n-0.9537006018079346 1.2361640304528203\n-1.3122834112374318 1.6276507531489064\n-0.038695509266051115 0.3380116965744758\n-1.6157723547032947 -1.199268032335186\n0.04359685683424694 -0.024616955875778355\n-0.6200008439481293 -0.7751616191691596\n0.6980320340722189 1.2737559301587766\n-0.9537006018079346 1.9671017492547347\n-0.26621850600362207 -1.857981864446752\n0.03261454669335856 1.2361640304528203\n-1.6157723547032947 1.6276507531489064\n1.121417708235664 0.3380116965744758\n0.4089005379368278 -1.199268032335186\n[[[[-0.809 -4.550 -5.486 -9.506 -4.512]\n   [-0.055  1.145 -5.388 -3.910  0.097]\n   [-0.186  0.660  1.630  2.275  4.874]\n   [ 2.386 -0.225  3.288 -4.239 -1.403]\n   [ 0.825  1.710 -3.246  3.246  1.709]\n   [ 0.809  3.695  3.491 -2.113 -2.714]]]]\n"
                }
            ],
            "source": "# Set random seed so we always get same answer\nnp.random.seed(1)\nn_batch = 1\nimage_height = 12\nimage_width = 10\nchannels_in = 1\nkernel_size = 3\nchannels_out = 1\nstride = 2\n\n# Create random input image\ninput_image= np.random.normal(size=(n_batch, channels_in, image_height, image_width))\n# Create random convolution kernel weights\nconv_weights = np.random.normal(size=(channels_out, channels_in, kernel_size, kernel_size))\n\n# Perform convolution using PyTorch\nconv_results_pytorch = conv_pytorch(input_image, conv_weights, stride, pad=1)\nprint(\"PyTorch Results\")\nprint(conv_results_pytorch)\n\n# Perform convolution in numpy\nprint(\"Your results\")\nconv_results_numpy = conv_numpy_2(input_image, conv_weights, stride, pad=1)\nprint(conv_results_numpy)"
        },
        {
            "cell_type": "markdown",
            "id": "4929cc01",
            "metadata": {},
            "source": "Now we'll introduce multiple input and output channels"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "8295db10",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "# Perform convolution in numpy\ndef conv_numpy_3(image, weights, stride=1, pad=1):\n\n    # Perform zero padding\n    if pad != 0:\n        image = np.pad(image, ((0, 0), (0 ,0), (pad, pad), (pad, pad)),'constant')\n\n    # Get sizes of image array and kernel weights\n    batchSize,  channelsIn, imageHeightIn, imageWidthIn = image.shape\n    channelsOut, channelsIn, kernelHeight, kernelWidth = weights.shape\n\n    # Get size of output arrays\n    imageHeightOut = np.floor(1 + (imageHeightIn - kernelHeight) / stride).astype(int)\n    imageWidthOut = np.floor(1 + (imageWidthIn - kernelWidth) / stride).astype(int)\n\n    # Create output\n    out = np.zeros((batchSize, channelsOut, imageHeightOut, imageWidthOut), dtype=np.float32)\n\n    for c_y in range(imageHeightOut):\n      for c_x in range(imageWidthOut):\n        for c_channel_out in range(channelsOut):\n          for c_channel_in in range(channelsIn):\n            for c_kernel_y in range(kernelHeight):\n              for c_kernel_x in range(kernelWidth):\n                  # TODO -- Retrieve the image pixel and the weight from the convolution\n                  # Only one image in batch so this index should be zero\n                  # Replace the two lines below\n                  p_y_index = c_y*stride\n                  p_x_index = c_x * stride\n                  this_pixel_value = image[0, c_channel_in, p_y_index + c_kernel_y, p_x_index + c_kernel_x]\n                  this_weight = weights[0, c_channel_in, c_kernel_y, c_kernel_x]\n\n                  # Multiply these together and add to the output at this position\n                  out[0, c_channel_out, c_y, c_x] += np.sum(this_pixel_value * this_weight)\n    return out"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "3cdefb4c",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "PyTorch Results\n[[[[ -0.785   5.463  -2.480   5.026  -3.594   7.785]\n   [ -6.744   2.534  -0.664   7.149  -9.839   7.849]\n   [ -4.794  14.074  -1.060   2.706 -10.182   2.004]\n   [  1.809   0.287   4.648  -1.840   3.259   1.073]]\n\n  [[  4.150   5.372   1.699   0.500   0.589   4.361]\n   [ -4.123   5.136   4.677  -3.895  -4.990   2.546]\n   [  3.991   5.768  -2.315   8.473   1.752   2.766]\n   [  1.529   0.318  11.518  -5.444  -2.293   1.270]]]]\nYour results\n[[[[ -0.785   5.463  -2.480   5.026  -3.594   7.785]\n   [ -6.744   2.534  -0.664   7.149  -9.839   7.849]\n   [ -4.794  14.074  -1.060   2.706 -10.182   2.004]\n   [  1.809   0.287   4.648  -1.840   3.259   1.073]]\n\n  [[ -0.785   5.463  -2.480   5.026  -3.594   7.785]\n   [ -6.744   2.534  -0.664   7.149  -9.839   7.849]\n   [ -4.794  14.074  -1.060   2.706 -10.182   2.004]\n   [  1.809   0.287   4.648  -1.840   3.259   1.073]]]]\n"
                }
            ],
            "source": "# Set random seed so we always get same answer\nnp.random.seed(1)\nn_batch = 1\nimage_height = 4\nimage_width = 6\nchannels_in = 5\nkernel_size = 3\nchannels_out = 2\n\n# Create random input image\ninput_image= np.random.normal(size=(n_batch, channels_in, image_height, image_width))\n# Create random convolution kernel weights\nconv_weights = np.random.normal(size=(channels_out, channels_in, kernel_size, kernel_size))\n\n# Perform convolution using PyTorch\nconv_results_pytorch = conv_pytorch(input_image, conv_weights, stride=1, pad=1)\nprint(\"PyTorch Results\")\nprint(conv_results_pytorch)\n\n# Perform convolution in numpy\nprint(\"Your results\")\nconv_results_numpy = conv_numpy_3(input_image, conv_weights, stride=1, pad=1)\nprint(conv_results_numpy)"
        },
        {
            "cell_type": "markdown",
            "id": "cb673920",
            "metadata": {},
            "source": "Now we'll do the full convolution with multiple images (batch size > 1), and multiple input channels, multiple output channels."
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "3e87cf03",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "# Perform convolution in numpy\ndef conv_numpy_4(image, weights, stride=1, pad=1):\n\n    # Perform zero padding\n    if pad != 0:\n        image = np.pad(image, ((0, 0), (0 ,0), (pad, pad), (pad, pad)),'constant')\n\n    # Get sizes of image array and kernel weights\n    batchSize,  channelsIn, imageHeightIn, imageWidthIn = image.shape\n    channelsOut, channelsIn, kernelHeight, kernelWidth = weights.shape\n\n    # Get size of output arrays\n    imageHeightOut = np.floor(1 + (imageHeightIn - kernelHeight) / stride).astype(int)\n    imageWidthOut = np.floor(1 + (imageWidthIn - kernelWidth) / stride).astype(int)\n\n    # Create output\n    out = np.zeros((batchSize, channelsOut, imageHeightOut, imageWidthOut), dtype=np.float32)\n\n    for c_batch in range(batchSize):\n      for c_y in range(imageHeightOut):\n        for c_x in range(imageWidthOut):\n          for c_channel_out in range(channelsOut):\n            for c_channel_in in range(channelsIn):\n              for c_kernel_y in range(kernelHeight):\n                for c_kernel_x in range(kernelWidth):\n                    # TODO -- Retrieve the image pixel and the weight from the convolution\n                    # Replace the two lines below\n                    p_y_index = c_y*stride\n                    p_x_index = c_x * stride\n                    this_pixel_value = image[c_batch, c_channel_in, p_y_index + c_kernel_y, p_x_index + c_kernel_x]\n                    this_weight = weights[c_batch, c_channel_in, c_kernel_y, c_kernel_x]\n\n                    # Multiply these together and add to the output at this position\n                    out[c_batch, c_channel_out, c_y, c_x] += np.sum(this_pixel_value * this_weight)\n\n    return out"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "26455077",
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "PyTorch Results\n[[[[ -3.633  -1.644   0.169  -1.167  -3.865   6.045]\n   [ -9.004   7.303   4.414   0.361  -6.739   3.939]\n   [ -1.391  13.502   3.807  -9.379   3.991   5.442]\n   [  2.805   6.874  -9.287  -4.468  -1.501   4.607]]\n\n  [[  1.940  -1.410   2.397  -0.235  -0.394  -1.483]\n   [  5.049  -3.335  -7.596  -1.586   3.049  -1.857]\n   [  3.514   0.475  -1.952  -1.291  -0.589  -0.948]\n   [  6.524  -0.020  -3.298  -1.248   3.249  -2.680]]]\n\n\n [[[  4.154  -4.764  11.635   0.506  -4.012  -2.081]\n   [ -1.125  -0.677  16.749  -7.030  -5.978  -2.629]\n   [  0.778  -3.984 -10.284   1.575  -8.888   1.163]\n   [  0.556  -2.290   1.407  -3.088   2.227  -5.403]]\n\n  [[  1.048   4.322  -0.901  -5.820   3.998   2.281]\n   [ -1.313   8.409  -0.100  14.625   1.223  -3.572]\n   [  1.411   1.617  -4.078  -8.107   3.705   0.229]\n   [ -3.540  -5.292  -5.619  -4.039  -4.048  -3.446]]]]\nYour results\n[[[[-3.633 -1.644  0.169 -1.167 -3.865  6.045]\n   [-9.004  7.303  4.414  0.361 -6.739  3.939]\n   [-1.391 13.502  3.807 -9.379  3.991  5.442]\n   [ 2.805  6.874 -9.287 -4.468 -1.501  4.607]]\n\n  [[-3.633 -1.644  0.169 -1.167 -3.865  6.045]\n   [-9.004  7.303  4.414  0.361 -6.739  3.939]\n   [-1.391 13.502  3.807 -9.379  3.991  5.442]\n   [ 2.805  6.874 -9.287 -4.468 -1.501  4.607]]]\n\n\n [[[ 1.048  4.322 -0.901 -5.820  3.998  2.281]\n   [-1.313  8.409 -0.100 14.625  1.223 -3.572]\n   [ 1.411  1.617 -4.078 -8.107  3.705  0.229]\n   [-3.540 -5.292 -5.619 -4.039 -4.048 -3.446]]\n\n  [[ 1.048  4.322 -0.901 -5.820  3.998  2.281]\n   [-1.313  8.409 -0.100 14.625  1.223 -3.572]\n   [ 1.411  1.617 -4.078 -8.107  3.705  0.229]\n   [-3.540 -5.292 -5.619 -4.039 -4.048 -3.446]]]]\n"
                }
            ],
            "source": "# Set random seed so we always get same answer\nnp.random.seed(1)\nn_batch = 2\nimage_height = 4\nimage_width = 6\nchannels_in = 5\nkernel_size = 3\nchannels_out = 2\n\n# Create random input image\ninput_image= np.random.normal(size=(n_batch, channels_in, image_height, image_width))\n# Create random convolution kernel weights\nconv_weights = np.random.normal(size=(channels_out, channels_in, kernel_size, kernel_size))\n\n# Perform convolution using PyTorch\nconv_results_pytorch = conv_pytorch(input_image, conv_weights, stride=1, pad=1)\nprint(\"PyTorch Results\")\nprint(conv_results_pytorch)\n\n# Perform convolution in numpy\nprint(\"Your results\")\nconv_results_numpy = conv_numpy_4(input_image, conv_weights, stride=1, pad=1)\nprint(conv_results_numpy)"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}